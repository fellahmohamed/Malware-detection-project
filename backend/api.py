import tensorflow as tf
from fastapi import FastAPI, File, UploadFile
from pydantic import BaseModel
from data_preprocessing import PEFeatureExtractor
from fastapi.responses import JSONResponse
import xgboost as xgb
import joblib
import pickle
import lightgbm as lgb
import tensorflow as tf
import numpy as np
import uvicorn
import traceback
from fastapi.middleware.cors import CORSMiddleware


feature_extractor = PEFeatureExtractor()


# with open(r"rufus-3.20.exe", 'rb') as f:
#     bytez = f.read()
# try:
#     print("mohamed")
#     feature_vector = feature_extractor.feature_vector(bytez)
# except :
#     traceback.print_exc()
# print(feature_vector)
# Load your models
xgboost_model = xgb.Booster()
xgboost_model.load_model('XGB_fold0.xgb')
model_path = 'trained_model_lgbm (1).pkl'

# Load the model
with open(model_path, 'rb') as file:
    lgb_model = pickle.load(file)
cnn_model = tf.keras.models.load_model('cnn_model_1.h5')
mlp_model = tf.keras.models.load_model('mlp.h5')

# origins = [
#     "http://localhost",  # Adjust as necessary for your frontend
#     "http://localhost:8000",  # Adjust as necessary for your frontend
#     "http://your-frontend-domain.com"  # Adjust as necessary for your frontend
app = FastAPI()
# ]
origins = ["*"]  # Allow requests from any origin

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# print(mlp_model.summary())



class PredictionResponse(BaseModel):
    xgboost: str
    lgbm: str
    cnn: str
    mlp: str

@app.post("/predict", response_model=PredictionResponse)
async def predict(file: UploadFile = File(...)):
    
    
    try:
        file_bytes = await file.read()
    except Exception as e:
        return JSONResponse(status_code=500, content={"message": str(e)})
    

   
    # Vectorize the PE file
  
    try:
     print("mohamed")
     feature_vector = feature_extractor.feature_vector(file_bytes)
    except :
      traceback.print_exc()
    print(feature_vector)
    sample= np.array(feature_vector).reshape(1,-1)
    scaler = joblib.load('scaler.joblib')
    pca=joblib.load('pca_model.joblib')
    mlp_sample=scaler.transform(sample)
    cnnsmaple=np.delete(mlp_sample, np.s_[-77:], axis=1)
   
    mlp_sample=pca.transform(mlp_sample)
    cnnsmaple=np.reshape(cnnsmaple,(1,48,48,1))




    # XGBoost prediction
    xgboost_dmatrix = xgb.DMatrix(sample)
    xgboost_prediction = xgboost_model.predict(xgboost_dmatrix)
    xgboost_result = 'malware' if xgboost_prediction[0] > 0.5 else 'benign'
    
    #lightgbm prediction
    lgbm_prediction = lgb_model.predict(sample)
    lgbm_result = 'malware' if lgbm_prediction[0] > 0.5 else 'benign'

    # CNN prediction
    cnn_prediction = cnn_model.predict(cnnsmaple)
    cnn_result = 'malware' if cnn_prediction[0][0] > 0.5 else 'benign'

    # MLP prediction
    mlp_prediction = mlp_model.predict(mlp_sample)
    mlp_result = 'malware' if mlp_prediction[0][0] > 0.5 else 'benign'

    return PredictionResponse(
        xgboost=xgboost_result,
        lgbm=lgbm_result,
        cnn=cnn_result,
        mlp=mlp_result
    )

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)




# with open(pe_file_path, 'rb') as f:
#     bytez = f.read()

# # Extract features from the PE file
# try:
#    feature_vector = feature_extractor.feature_vector(bytez)
# except :
#     traceback.print_exc()
# sample= np.array(feature_vector).reshape(1,-1)

# loaded_model = xgb.Booster()
# loaded_model.load_model('XGB_fold0.xgb')
# dtest=xgb.DMatrix(sample)

# y_pred = loaded_model.predict(dtest)

# # Convert predicted probabilities to class labels
# y_pred_labels = np.round(y_pred)

# # Calculate accuracy
# print(y_pred_labels)