{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a80067-cbd3-454e-83d4-bacc09097834",
   "metadata": {},
   "source": [
    "# XGBOOST model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316aaeb4-284d-401c-8dce-363d83ddd211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext cudf.pandas\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30f0b7d-b8ac-4679-8446-3bb981c73747",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_np =np.memmap(\"x_train_all.data\", dtype='float32', mode='r',shape=(600000,2381) )\n",
    "y_train_np =np.memmap(\"y_train_all.data\", dtype='float32', mode='r',shape=600000 )\n",
    "x_test_np =np.memmap(\"x_test.data\", dtype='float32', mode='r',shape=(200000,2381) )\n",
    "y_test_np =np.memmap(\"y_test.data\", dtype='float32', mode='r',shape=200000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81eae534-abd8-492b-b0f5-b21dc750201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df=pd.DataFrame(x_train_np)\n",
    "y_train_df=pd.DataFrame(y_train_np)\n",
    "x_test_df=pd.DataFrame(x_test_np)\n",
    "y_test_df=pd.DataFrame(y_test_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b75ee37-82e6-4c66-a0fa-fe641901fa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2371</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.184524</td>\n",
       "      <td>0.031308</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>92936.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>442296.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.251737</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.023493</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>37280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008964</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.003939</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020401</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.014676  0.004222  0.003923  0.004029  0.004007  0.003775  0.003825   \n",
       "1  0.184524  0.031308  0.005693  0.005959  0.008144  0.003512  0.005786   \n",
       "2  0.251737  0.014205  0.006841  0.008556  0.023493  0.002858  0.003401   \n",
       "3  0.008964  0.004055  0.003925  0.003936  0.004037  0.003878  0.003847   \n",
       "4  0.020401  0.005213  0.004519  0.004097  0.004240  0.004029  0.003785   \n",
       "\n",
       "       7         8         9     ...  2371     2372   2373   2374    2375  \\\n",
       "0  0.003887  0.004153  0.003804  ...  72.0  35240.0    0.0    0.0   660.0   \n",
       "1  0.008550  0.009141  0.001791  ...  64.0  92936.0  408.0  608.0  2604.0   \n",
       "2  0.008556  0.010215  0.001176  ...   0.0      0.0    0.0    0.0  1120.0   \n",
       "3  0.003946  0.003939  0.003834  ...   0.0      0.0    0.0    0.0     0.0   \n",
       "4  0.004593  0.004875  0.003780  ...   0.0      0.0    0.0    0.0   520.0   \n",
       "\n",
       "      2376   2377      2378  2379  2380  \n",
       "0  32768.0    0.0       0.0   0.0   0.0  \n",
       "1   4096.0  224.0  442296.0   0.0   0.0  \n",
       "2   4096.0  192.0   37280.0   0.0   0.0  \n",
       "3      0.0    0.0       0.0   0.0   0.0  \n",
       "4   4096.0    0.0       0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 2381 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9426fec4",
   "metadata": {},
   "source": [
    "## training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6707798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "xgb_parms = { \n",
    "    'max_depth':4, \n",
    "    'learning_rate':0.05, \n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.6, \n",
    "    'eval_metric':'logloss',\n",
    "    'objective':'binary:logistic',\n",
    "    'tree_method':'gpu_hist',\n",
    "    'predictor':'gpu_predictor',\n",
    "    'random_state':SEED\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30d792a-fb97-412f-86ec-617fac3f827e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 480000 Valid size 120000\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [19:00:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [19:00:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.67023\tvalid-logloss:0.67036\n",
      "[100]\ttrain-logloss:0.25050\tvalid-logloss:0.25327\n",
      "[200]\ttrain-logloss:0.19667\tvalid-logloss:0.20034\n",
      "[300]\ttrain-logloss:0.16999\tvalid-logloss:0.17427\n",
      "[400]\ttrain-logloss:0.15353\tvalid-logloss:0.15841\n",
      "[500]\ttrain-logloss:0.14127\tvalid-logloss:0.14655\n",
      "[600]\ttrain-logloss:0.13130\tvalid-logloss:0.13719\n",
      "[700]\ttrain-logloss:0.12332\tvalid-logloss:0.12956\n",
      "[800]\ttrain-logloss:0.11646\tvalid-logloss:0.12315\n",
      "[900]\ttrain-logloss:0.11087\tvalid-logloss:0.11808\n",
      "[1000]\ttrain-logloss:0.10596\tvalid-logloss:0.11361\n",
      "[1100]\ttrain-logloss:0.10139\tvalid-logloss:0.10947\n",
      "[1200]\ttrain-logloss:0.09748\tvalid-logloss:0.10608\n",
      "[1300]\ttrain-logloss:0.09397\tvalid-logloss:0.10302\n",
      "[1400]\ttrain-logloss:0.09076\tvalid-logloss:0.10035\n",
      "[1500]\ttrain-logloss:0.08745\tvalid-logloss:0.09745\n",
      "[1600]\ttrain-logloss:0.08477\tvalid-logloss:0.09515\n",
      "[1700]\ttrain-logloss:0.08191\tvalid-logloss:0.09270\n",
      "[1800]\ttrain-logloss:0.07937\tvalid-logloss:0.09062\n",
      "[1900]\ttrain-logloss:0.07709\tvalid-logloss:0.08883\n",
      "[2000]\ttrain-logloss:0.07500\tvalid-logloss:0.08720\n",
      "[2100]\ttrain-logloss:0.07277\tvalid-logloss:0.08538\n",
      "[2200]\ttrain-logloss:0.07082\tvalid-logloss:0.08389\n",
      "[2300]\ttrain-logloss:0.06888\tvalid-logloss:0.08234\n",
      "[2400]\ttrain-logloss:0.06701\tvalid-logloss:0.08091\n",
      "[2500]\ttrain-logloss:0.06532\tvalid-logloss:0.07967\n",
      "[2600]\ttrain-logloss:0.06363\tvalid-logloss:0.07836\n",
      "[2700]\ttrain-logloss:0.06216\tvalid-logloss:0.07726\n",
      "[2800]\ttrain-logloss:0.06069\tvalid-logloss:0.07621\n",
      "[2900]\ttrain-logloss:0.05917\tvalid-logloss:0.07510\n",
      "[3000]\ttrain-logloss:0.05778\tvalid-logloss:0.07409\n",
      "[3100]\ttrain-logloss:0.05641\tvalid-logloss:0.07312\n",
      "[3200]\ttrain-logloss:0.05510\tvalid-logloss:0.07221\n",
      "[3300]\ttrain-logloss:0.05386\tvalid-logloss:0.07137\n",
      "[3400]\ttrain-logloss:0.05269\tvalid-logloss:0.07054\n",
      "[3500]\ttrain-logloss:0.05154\tvalid-logloss:0.06978\n",
      "[3600]\ttrain-logloss:0.05035\tvalid-logloss:0.06893\n",
      "[3700]\ttrain-logloss:0.04914\tvalid-logloss:0.06812\n",
      "[3800]\ttrain-logloss:0.04806\tvalid-logloss:0.06743\n",
      "[3900]\ttrain-logloss:0.04701\tvalid-logloss:0.06674\n",
      "[4000]\ttrain-logloss:0.04601\tvalid-logloss:0.06612\n",
      "[4100]\ttrain-logloss:0.04503\tvalid-logloss:0.06548\n",
      "[4200]\ttrain-logloss:0.04411\tvalid-logloss:0.06490\n",
      "[4300]\ttrain-logloss:0.04324\tvalid-logloss:0.06436\n",
      "[4400]\ttrain-logloss:0.04237\tvalid-logloss:0.06381\n",
      "[4500]\ttrain-logloss:0.04148\tvalid-logloss:0.06326\n",
      "[4600]\ttrain-logloss:0.04067\tvalid-logloss:0.06275\n",
      "[4700]\ttrain-logloss:0.03988\tvalid-logloss:0.06228\n",
      "[4800]\ttrain-logloss:0.03910\tvalid-logloss:0.06182\n",
      "[4900]\ttrain-logloss:0.03833\tvalid-logloss:0.06141\n",
      "[5000]\ttrain-logloss:0.03756\tvalid-logloss:0.06094\n",
      "[5100]\ttrain-logloss:0.03676\tvalid-logloss:0.06044\n",
      "[5200]\ttrain-logloss:0.03604\tvalid-logloss:0.06005\n",
      "[5300]\ttrain-logloss:0.03533\tvalid-logloss:0.05966\n",
      "[5400]\ttrain-logloss:0.03464\tvalid-logloss:0.05926\n",
      "[5500]\ttrain-logloss:0.03395\tvalid-logloss:0.05886\n",
      "[5600]\ttrain-logloss:0.03328\tvalid-logloss:0.05848\n",
      "[5700]\ttrain-logloss:0.03264\tvalid-logloss:0.05813\n",
      "[5800]\ttrain-logloss:0.03201\tvalid-logloss:0.05777\n",
      "[5900]\ttrain-logloss:0.03139\tvalid-logloss:0.05743\n",
      "[6000]\ttrain-logloss:0.03081\tvalid-logloss:0.05713\n",
      "[6100]\ttrain-logloss:0.03024\tvalid-logloss:0.05679\n",
      "[6200]\ttrain-logloss:0.02968\tvalid-logloss:0.05647\n",
      "[6300]\ttrain-logloss:0.02911\tvalid-logloss:0.05617\n",
      "[6400]\ttrain-logloss:0.02856\tvalid-logloss:0.05590\n",
      "[6500]\ttrain-logloss:0.02801\tvalid-logloss:0.05559\n",
      "[6600]\ttrain-logloss:0.02746\tvalid-logloss:0.05528\n",
      "[6700]\ttrain-logloss:0.02694\tvalid-logloss:0.05503\n",
      "[6800]\ttrain-logloss:0.02642\tvalid-logloss:0.05476\n",
      "[6900]\ttrain-logloss:0.02592\tvalid-logloss:0.05456\n",
      "[7000]\ttrain-logloss:0.02545\tvalid-logloss:0.05430\n",
      "[7100]\ttrain-logloss:0.02498\tvalid-logloss:0.05404\n",
      "[7200]\ttrain-logloss:0.02452\tvalid-logloss:0.05383\n",
      "[7300]\ttrain-logloss:0.02407\tvalid-logloss:0.05359\n",
      "[7400]\ttrain-logloss:0.02364\tvalid-logloss:0.05340\n",
      "[7500]\ttrain-logloss:0.02321\tvalid-logloss:0.05320\n",
      "[7600]\ttrain-logloss:0.02279\tvalid-logloss:0.05301\n",
      "[7700]\ttrain-logloss:0.02234\tvalid-logloss:0.05280\n",
      "[7800]\ttrain-logloss:0.02193\tvalid-logloss:0.05260\n",
      "[7900]\ttrain-logloss:0.02150\tvalid-logloss:0.05239\n",
      "[8000]\ttrain-logloss:0.02110\tvalid-logloss:0.05220\n",
      "[8100]\ttrain-logloss:0.02070\tvalid-logloss:0.05198\n",
      "[8200]\ttrain-logloss:0.02031\tvalid-logloss:0.05180\n",
      "[8300]\ttrain-logloss:0.01993\tvalid-logloss:0.05165\n",
      "[8400]\ttrain-logloss:0.01957\tvalid-logloss:0.05149\n",
      "[8500]\ttrain-logloss:0.01922\tvalid-logloss:0.05133\n",
      "[8600]\ttrain-logloss:0.01886\tvalid-logloss:0.05118\n",
      "[8700]\ttrain-logloss:0.01852\tvalid-logloss:0.05101\n",
      "[8800]\ttrain-logloss:0.01819\tvalid-logloss:0.05086\n",
      "[8900]\ttrain-logloss:0.01786\tvalid-logloss:0.05069\n",
      "[9000]\ttrain-logloss:0.01752\tvalid-logloss:0.05054\n",
      "[9100]\ttrain-logloss:0.01720\tvalid-logloss:0.05043\n",
      "[9200]\ttrain-logloss:0.01688\tvalid-logloss:0.05030\n",
      "[9300]\ttrain-logloss:0.01658\tvalid-logloss:0.05017\n",
      "[9400]\ttrain-logloss:0.01628\tvalid-logloss:0.05005\n",
      "[9500]\ttrain-logloss:0.01599\tvalid-logloss:0.04992\n",
      "[9600]\ttrain-logloss:0.01569\tvalid-logloss:0.04978\n",
      "[9700]\ttrain-logloss:0.01540\tvalid-logloss:0.04967\n",
      "[9800]\ttrain-logloss:0.01512\tvalid-logloss:0.04957\n",
      "[9900]\ttrain-logloss:0.01485\tvalid-logloss:0.04946\n",
      "[9998]\ttrain-logloss:0.01460\tvalid-logloss:0.04936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [19:21:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [19:21:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGB_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xgb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dvalid)\n\u001b[1;32m---> 21\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetric =\u001b[39m\u001b[38;5;124m'\u001b[39m,acc,\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "k_folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, val_idx) in enumerate(k_folds.split(x_train_df, y_train_df)):\n",
    "    print('#'*25)\n",
    "    print('### Fold',fold+1)\n",
    "    print('### Train size',len(train_idx),'Valid size',len(val_idx))\n",
    "    print('#'*25)\n",
    "    x_train= x_train_df.iloc[train_idx]\n",
    "    x_val= x_train_df.iloc[val_idx]\n",
    "    y_train= y_train_df.iloc[train_idx]\n",
    "    y_val= y_train_df.iloc[val_idx]\n",
    "    dtrain=xgb.DMatrix(x_train,label=y_train)\n",
    "    dvalid=xgb.DMatrix(x_val,label=y_val)\n",
    "    model = xgb.train(xgb_parms, \n",
    "                dtrain=dtrain,\n",
    "                evals=[(dtrain,'train'),(dvalid,'valid')],\n",
    "                num_boost_round=9999,\n",
    "                early_stopping_rounds=100,\n",
    "                verbose_eval=100)\n",
    "    model.save_model(f'XGB_fold{fold}.xgb')\n",
    "    preds = model.predict(dvalid)\n",
    "    acc = accuracy_score(y_val,preds)\n",
    "    print('Metric =',acc,'\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9562be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model('XGB_fold0.xgb')\n",
    "dtest=xgb.DMatrix(x_test_df)\n",
    "\n",
    "y_pred = loaded_model.predict(dtest)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_labels = np.round(y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd74196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[97430  2570]\n",
      " [ 2845 97155]]\n",
      "Accuracy: 0.972925\n",
      "Precision: 0.9742291301077964\n",
      "Recall: 0.97155\n",
      "F1 Score: 0.9728877206158468\n",
      "False Positives: 2570\n",
      "False Positives Percentage: 1.2850000000000001\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_df, y_pred_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_df, y_pred_labels)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test_df, y_pred_labels)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test_df, y_pred_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test_df, y_pred_labels)\n",
    "\n",
    "# Calculate false positives (FP)\n",
    "fp = cm[0, 1]  # FP is the value at row 0, column 1 in the confusion matrix\n",
    "\n",
    "# Calculate the total number of samples\n",
    "total_samples = len(y_test_df)\n",
    "\n",
    "# Calculate the percentage of false positives\n",
    "fp_percentage = (fp / total_samples) * 100\n",
    "\n",
    "# Display the metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Positives Percentage:\", fp_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e267dd95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
